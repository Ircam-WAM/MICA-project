title: Program2
status: hidden
<br>

---

# Workshop, Dec. 11th Morning
## Theme : Instruments, spaces, bodies
<br>

####09:30
###Presentation of the ExCITe Center and the MET-lab
Yougmoo Kim (Drexel University)	

The ExCITe Center is Drexel University’s home for research and discovery connecting technology and creative expression, bringing together faculty and students from across the University to pursue transdisciplinary, collaborative projects. As part of the Center, the Music & Entertainment Technology Laboratory (MET-lab) focuses on the machine understanding of audio, human-machine interfaces and robotics for expressive interaction, real-time analysis, synthesis, and visualization of sound, and K-12 outreach for STEAM (Science, Technology, Engineering, Arts & Design, and Mathematics) education. This presentation will highlight recent MET-lab/ExCITe projects with external collaborators, including Sophia’s Forrest (a chamber opera with electroacoustic sound sculptures by composer Lembit Beecher) and a dance work involving autonomous drones, created with Parsons Dance.

###Augmentation of Acoustic Drums using Electromagnetic Actuation and Wireless Control	
Jeff Gregorio (Drexel University)  

We present a system for augmentation of acoustic drums using electromagnetic actuation of the resonant membrane, driven with continuous audio signals. Use of combinations of synthesized tones and feedback taken from the batter membrane extends the timbral and functional range of the drum. The system is designed to run on an embedded, WiFi-enabled platform, allowing multiple augmented drums to serve as voices of a spatially-distributed polyphonic synthesizer. Semi-autonomous behavior is also explored, with individual drums configured as nodes in a directed graph. EM actuation and wireless connectivity enables a network of augmented drums to function in traditionally percussive roles, as well as harmonic, melodic, and textural roles. This work is developed by an engineer in close collaboration with an artist in residence for use in live performance and interactive sound installation.

<br>
####10:15

###ONE and John: Oriented Improvisation
Pierre Couprie (Sorbonne University), Gyorgy Kurtag Jr (SCRIME, Bordeaux University)	

During this talk, we will present a French improvisation group in electroacoustic music: ONE (Orchestre National Electroacoustique). In this group, we have developed our instrument and/or the digital part of our devices. We also use a digital conductor called 'John' which propose an improvisation score for each musician from a list of words, nuances and variation of intensity. We also discuss the analysis of performance through representation technic to study John's influence on musical improvisation.

###The Djazz project: Jazz machines and Anthropology
Marc Chemillier (EHESS)  

Djazz belongs to the family of improvisation softwares called OMax/ImproteK/Djazz designed by IRCAM and EHESS. Its distinctiveness is that it is adapted to the interaction with jazz and world musicians in real social contexts, and as such is the subject of an anthropological survey dealing with rhythm and the way people synchronize themselves to the music during particular social events (dance rituals, concerts). We’ll show how rhythm is handled in Djazz and make a demo with Malagasy guitarist Charles Kely Zana-Rotsy.  

###Smart Acoustic Instruments: From Early Research to HyVibe
Adrien Mamou-Mani (HyVibe)  

Smart acoustic instruments are acoustic instruments with programmable sounds. I will present the research at the origin of this concept and examples of prototypes that have been used by artists. The emphasis will be put on the HyVibe Guitar, designed to be the future of electro-acoustic guitars, using digital technology and vibration control. Finally, I will share first ideas on its potential use for improvisation.

###Revolutionizing the Tradition: Extracting Human Expression using Motion Sensor for Music
Mari Kimura (UC Irvine)  

Violinist and composer Mari Kimura will discuss creating performances and compositions that integrate interactive computer, and the use of a motion sensor she has been developing. The lecture includes demonstrations including musical performances with her current prototype model “Mugic”, and her work with students at her summer program “Future Music Lab” she directs at the Atlantic Music Festival in collaboration with IRCAM, and in her classroom at her new ‘home’, “Integrated Composition, Improvisation and Technology” (ICIT) program at the Music Department of University of California, Irvine.

<br>
### 12:45 Lunch Break
<br>

---

# Workshop, Dec. 11th Afternoon
## Theme : Instruments, spaces, bodies
<br>

####14:30
###MIGSI: The Minimally Invasive Gesture Sensing Interface for Trumpet
Sarah Reid (CalArts)  

Performer-composer-technologist Sarah Reid will introduce the Minimally Invasive Gesture Sensing Interface (MIGSI) for trumpet. MIGSI uses sensor technology to capture gestural data such as valve displacement, hand tension, and instrument position, to offer extended control and expressivity to trumpet players. In addition to addressing technical and design-based considerations of MIGSI, this presentation will discuss various strategies for performing and composing with this new instrument, and will delve into a larger discussion on integrating new musical interfaces, micro-controllers, and electronic instruments into an improvisational practice.

###Denis Beuret
(to be completed)  

###Body/Environment couplings through sound and light  
Mina Zarfsaz  

This talk/demo is about an interactive audio/video piece that is consisted of a system of sensors, speakers, and projectors measuring the impact of movement and human organization as it reconstructs the dismantled fragments of pieces of music with any given group of people. Like an orchestra of instruments, it is the body of the spectator that co-composes the rhythmic content by co-ordinating movements with others as they trigger the sensors. The “notes” in this project are struck at the interface of body and machine. While in the space, each person is either an active “ON” (within a sensor range) or a passive “OFF” (out of a sensor range.) This piece forces one’s perceptual system to search the space for triggered sounds and lit surfaces; to track changes, estimate distances and corporeal relationship with others. The piece never repeats itself exactly, has no beginning, middle or end.

###Ableton Presentation
(to be completed)  

###Sound and Algorithmic Environments for Improvisation
Matthew Goodheart (Rensselaer Poly. Inst.)  

Reembodied sound is a form of electroacoustics that uses transducer-driven resonant objects to create acoustic realizations of sample and analysis derived mixed synthesis. This talk will focus on the use of reembodied sound as a generative basis to create large-scale, algorithmically driven sonic environments for improvisers, discussing both technical implementation and aesthetic orientation. Directions for future research involving digital listening agents and interactivity will also be addressed.

###Canopy of Catastrophes
Bhob Rainey  

What are some good ways, when making music that is shared among humans (and, in terms of appreciation, likely only among humans), to “get outside yourself” and connect to non-human patterns, entities, signals, etc., without pretending to be objective? Can you not only point to or represent the “great outdoors” but also bring yourself and maybe your audience "outside”? Are computers and computational thinking at all helpful in answering these questions? Let’s talk sonification and data streams and generative patterns, but let’s also ask how they function aesthetically, what ends they might serve when sounds reach ears and that communal event we call music happens.

<br>
###18:00 End of Dec. 11 sessions
<br>

---

# Workshop, Dec. 12th Morning
## Theme : Composition, Notation, Synthesis, Form
<br>

####09:30
### Keynote presentation by Bob Ostertag

<br>
####10:15
Recent Trends in Pulse-Based Improvisation, Rhythm Cognition, and some Potential Applications for Interactive Design
Steve Lehman (CalArts)	

Recent work in the domain of computer-driven improvisation has privileged modes of interactivity that eschew tempo-based hierarchies of musical time. This talk will seek to interrogate some of these recent tendencies, and provide a brief overview of the speaker's recent work integrating improvisation with contemporary research in the field of rhythmic cognition. Some potential applications to tempo-based musical models for human-computer interaction will also be discussed.
10:45	Joo Won Park (Wayne State U.)	composition strategies	compo		100 Strange Sounds: Practice on Electroacoustic Improvisation	100 Strange Sounds consists of one hundred video recordings of solo improvisations using live electronics http://www.100strangesounds.com. The purpose of this project was to improve the creator's technical and improvisational abilities while examining the documentation and promotional possibilities of an online video platform. The author will present the technical and aesthetic findings in completing the project by demonstrating the software and hardware setup as well as sharing the viewer data from Youtube and Google Analytics.

###Portable Gold and Philosophers' Stones (Deviant Resonances)
David Rosenboom (CalArts)	

The “Philosopher’s Stone” is a mental symbol about the prima materia, the original substance and ultimate principle of the universe. It has been said that by returning from the qualities of sensation and thought, which we perceive through differentiation and specialization, to the undifferentiated purity of the prima materia, we might learn truths about creative power and the fundamental mutability of all phenomena. Combining this with the symbol, Portable Gold, was my way of emphasizing the timelessness and spacelessness of this idea, which we can carry with us anywhere. To manifest these symbols in music, I’ve made pieces that work with resonant coincidences detected among the physical brainwaves of performers and apply them inside the circuits of custom-built, live electronic music devices, to grow spontaneous musical forms. This version is realized with portable brainwave detectors, computer music software, and an auxiliary acoustic instrument.
Portable Gold and Philosophers' Stones (1972 & 2015), Computer-electronics with BCMI (Brain-Computer Music Interface), auxiliary instrument, and two active imaginative listening brainwave performers (volunteers).

###Live Scoring for Computer Assisted Composition	
Justin Yang (RPI)

This talk explores the use of networked computer animation as a front end for composition and scoring for live performers. An assortment of computer animated graphic tools can be used to develop interactions between algorithms and AI, and live performers. These tools help open the door for possibilities such as real-time scoring, structured improvisation, multi-nodal composition, real-time orchestration, and performer-computer interactions.

###Constructing new Improvisation Instruments with Geometrical Configuration Space
Dmitri Tymoczko	with Rudresh Mahantappa  

We will show how how geometry can be used to construct new musical instruments based on the idea of a configuration space.  we will provide some examples of these indigenous electronic instruments and explain how they might be used in performance.

<br>
###13:00 Lunch Break
<br>

---

# Workshop, Dec. 12th Afternoon
## Theme : Composition, Notation, Synthesis, Form
<br>

####14:00
###Spatial constructs and concepts, rituals	
John Malia and Scott Deal (NEC studio)	

John Mallia lives and works in Boston, where he is a member of the Composition Faculty, and directs the Electronic Music Studio, at the New England Conservatory of Music. His compositional process is informed by spatial constructs and concepts, and a fascination with presence, ritual, and the thresholds standing between states of existence or awareness. In addition to composing chamber music and works combining acoustic instruments with electronics, he creates fixed media compositions, and collaborates with visual artists on multimedia works, including installation.

###Jeff Snyder
(to be completed)

###Improvising with Ensemble Feedback Instruments and First-order Cybernetic Followers
Matt Wright (CCRMA, Stanford University)  

Ensemble Feedback Instruments (first presented at NIME 2015) show that even extremely simple individual musical "instruments", if they each have an audio input as well as an audio output, can give rise to rich and varied musical behaviors when patched together in various feedback topologies. As long as there is just a little system delay, on the order of trained musicians' reaction times, then even unstable "exploding" systems can safely generate glorious crescendos when one or more careful listeners have low-latency gain controls in the loop allowing them to attenuate when things begin to get out of control. Taking this a step further, we can automate this "turn down when it gets too loud" behavior; we reframe the behavior of a side-chained compressor-limiter in terms of a first-order cybernetic feedback system like a thermostat.  Each sound element inside the feedback network can have a "goal" volume (analogous to a thermostat's temperature setting) and limited (i.e., time-slewed) ability to adjust its own output volume (analogous to turning the heater on or off) according to the volume it detects in its input or output signals and/or the ensemble's overall level (analogous to the thermometer). Again the simplest of elements can give rise to rich behaviors when placed in proper recursive context. Automating this guarantee that the potentially unstable ensemble feedback network will never blow up allows a shift from a model where a human performer directly controls each individual instrument to a model where a human performer might indirectly control multiple instruments at the same time and/or improvise in real-time collaboration with goal-seeking, if not "intelligent," software agents. 

###Drop for bassoon and electronics	
Katarina Miljkovic and Chris Watford		

Fabric of the electronic and instrumental part in the composition is derived from the structure of an automaton. Resulting sound events are of a modular nature and provide a field of possibilities for performers. During the performance, both performers traverse through the automaton by freely selecting sound modules while using the automaton data as time brackets. Live sound processing is happening through plugins. As a result, CA generates the structure, dictates the overall process but also embraces indeterminacy coming from a human response to a deterministic nature of the automaton, and an attempt to communicate with it. The piece is 12' long (there is also a version 24’ long). Sonic material is based on a field recording of a lament song from Balkans. The field recording is filtered through CA to create sound modules, which are treated in the way previously described.

<br>
####16:00	BREAK			

####16:30	
###ROUND TABLE : David Wessel Legacy, the researcher / musician
With Roscoe Mitchell, Matt Wright, Marc Chemillier, George Bloch

####17:45
###Coughing is a Form of Love	
Joseph Pfender & Melanie Farley 	
This performance was born out of a shared interest in creating new expressive resources at the seam of the human and the algorithmic. The vocal experiment embodies the vulnerability of vocal expression, and attempts to disrupt that vulnerability by introducing chance robotic interventions, creating a kind of cyborg poetry. Drawing on the energy of groups like Pere Ubu and Patti Smith, the poetry also takes substantive inspiration from Yoko Onoâ€™s instruction poems. The patch itself responds to historical avant-garde methods of recursive feedback, using sound synthesis and convolution procedures that have a topological affinity to David Tudorâ€™s Toneburst. Taking a cue from earlier forays into instrumental belligerence and productive obstruction at NIME, we attempt to work into vocalic expressivity a logic of resistance and effervescence.

###Generative patches for Modular and Semi-Modular Synthesizers
Sandy James (Temple U.)
(to be completed)

###Density Function
Adam Vidiksis + BEEP (Temple U.)  
(to be completed)

<br>
###18:30 Cocktail
<br>

---

#Workshop, Dec. 13th Morning
##Theme : Instruments, spaces, bodies
<br>

####09:30









