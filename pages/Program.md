title: Program

---

## Evening concerts on dec. 11th and 13h

### Prince Theater, Annenberg Center for the Performing arts (dec. 11th, 8pm)
*3680 Walnut St, Philadelphia, PA 19104*  

Marie Kimura, Gyorgy Kurtag, Pierre Couprie (violin,synths,computer interaction)  
Steve Lehman + Hprizm  (Sax, voice, electronics)  
Bernard Lubat + Marc Chemillier, Gérard Assayag (piano, voice, Omax/ImproteK system)  
Roscoe Mitchell (reeds)  
Bob Ostertag (keyboards)  
David Rosenboom  (piano, spatialization system, computer interaction)  
LaDonna Smith, Susan Alcorn, Anastasia Georgaki (violin, pedal steel, accordion, electronics)  
Michael Young  (piano, piano-prosthesis system)  

### The Rotunda (dec. 13th, 8pm)
*4014 Walnut Street, Philadelphia, PA 19104*  

Denis Beuret (trombone, live electronics)  
Georges Bloch, Rémy Fox, Michelle Agnes Magalhaes (ImproteK system, Saxophone, piano)  
Max Eilbacher (electronics)  
Charles Kely, Marc Chemillier (guitar, djazz system)  
Moor Mother (voice, electronics)  
Dana Naphtali (electronics)  
Bhob Rainey  
Lance Simmons, Ada Babar (electronics, prepared guitar)  
Adam Vidiksis (percussion, electronics)  

---

## Workshop on dec 11-13th (9:30am - 6pm)
*U. Penn, Lerner Center, Rm 101, 201 S 34th St*  
*U. Penn, Fisher-Bennett Hall	419 Rose Hall, 3340 Walnut St*  

### Keynotes speaker

Bob Ostertag (UC Davis)  
David Rosenboom (CalArts)

### Round Table : hommage to David Wessel
Roscoe Mitchell, Marc Chemillier (EHESS), Richard S. Andrew (CNMAT), Georges Bloch (U. Strasbourg)...

### Presentations, demos, performances
<br>
####Intelligent Music Agents capable of joint intuitive and rational thinking
Jonas Braasch (RPI)  
This talk describes an intelligent music system approach that utilizes a joint bottom-up/top-down structure. The bottom-up structure is purely signal driven and calculates pitch, loudness, and information rate among other parameters using auditory models that simulate the functions of different parts of the brain. The top-down structure builds on a logic-based reasoning system and an ontology that was developed to reflect rules in jazz practice. Two instances of the agent have been developed to perform traditional and free jazz, and it is shown that the same general structure can be used to improvise different styles of jazz.

####Live Scoring for Computer Assisted Composition
Justin Yang	(RPI)  
This talk explores the use of networked computer animation as a front end for composition and scoring for live performers. An assortment of computer animated graphic tools can be used to develop interactions between algorithms and AI, and live performers. These tools help open the door for possibilities such as real-time scoring, structured improvisation, multi-nodal composition, real-time orchestration, and performer-computer interactions.

####Reembodied Sound and Algorithmic Environments for Improvisation
Matthew Goodheart (RPI)  
Reembodied sound is a form of electroacoustics that uses transducer-driven resonant objects to create acoustic realizations of sample and analysis derived mixed synthesis. This talk will focus on the use of reembodied sound as a generative basis to create large-scale, algorithmically driven sonic environments for improvisers, discussing both technical implementation and aesthetic orientation. Directions for future research involving digital listening agents and interactivity will also be addressed.

####Mediation between Musicians and Code with Neural Networks
Jeremy Stewart (RPI)  
For this talk, we will discuss design and implementation of a neural network system for performance between acoustic musicians and live coding performers. Starting with simple classification systems and experimenting with data for training deep neural networks, while also considering novel integrations into existing performance systems, we will outline our current work while also discussing potential steps forward.

####Matmos presentation	
Matmos  
Matmos presentation


####Ableton Presentation
Ben Casey (Ableton)  
Ableton tech update for improvisers

####Digital feedback driven by spoken word
Joseph Pfender  
Multichannel speaker array to produce digital feedback and live cepstral analysis that is driven by spoken word

####Density Function
Adam Vidiksis + BEEP (Temple U.)  
Presentation and perfromance by percussionist & student laptop ensemble

####From OMAX to DYCI2
Jérôme Nika (Ircam), Ken Deguernel (Inria), Rémy Fox (Saxophone)  
From the  Omax improvisation software to the new DYCI2 project (Creative Dynamics of Improvised Interaction)

####The djazz project
Marc Chemillier	(EHESS)  
Jazz machines and anthropology

####Portable Gold and Philosophers’ Stones (Deviant Resonances)	
David Rosenboom	(CalArts)  
Presentation and performance of David Rosenboom piece : Computer-electronics, auxiliary instrument (ex. electric violin, piano, DisklavierTM), two active imaginative listening brainwave performers (volunteers available for one orientation/rehearsal), and video projection

####Improvising / Analysing in the electroacoustic esthetics
Pierre Couprie (Sorbonne University), Gyorgy Kurtag (SCRIME, Bordeaux University)  
Improvising in the electroacoustic esthetics

####Interaction, rhythm cognition, digital muscianship	
Steve Lehman (CalArts)  
interaction, rhythm cognition, digital muscianship	

####The Violin / Machine Muscianship
Mari Kimura	(UC Irvine)  
The Violin / Machine Muscianship

####Soundscapes as interfaces for data-driven musical possibilities
Tae Hong Park (NYU)  
Hands-on, people can bring laptop running their favorite music app - e.g. Max, supercollider, etc.

####NYU MARL activity Overview	
Tae Hong Park (NYU)  
MARL: Music and Audio Research Laboratory / DEPARTMENT OF MUSIC AND PERFORMING ARTS PROFESSIONS / Computer Music & Interactive Performance group

####NYU Students Works
NYU Music Students	
NYU	 Students Works

####Experimental electronics of the American Midwest
Max Eilbacher  
experimental electronics of the American Midwest (Sonic Arts Union aka Robert Ashley, Alvin Lucier, Gordon Mumma, etc)

####Canopy of Catastrophes<br>
Bhob Rainey<br>
What are some good ways, when making music that is shared among humans (and, in terms of appreciation, likely only among humans), to “get outside yourself” and connect to non-human patterns, entities, signals, etc., without pretending to be objective? Can you not only point to or represent the “great outdoors” but also bring yourself and maybe your audience "outside”? Are computers and computational thinking at all helpful in answering these questions? Let’s talk sonification and data streams and generative patterns, but let’s also ask how they function aesthetically, what ends they might serve when sounds reach ears and that communal event we call music happens.

####The smart instrument project	
Adrien Mamou-Mani (HyVibe)
The smart instrument project. With Charles Kely.

####Piano Prosthesis, Live Algorithms for Music	
Michael Young (U. of Sunderland)
Can computers be creative? How would we know? The Live Algorithms for Music network explores such questions in the context of live improvisation

####Drexel MET Lab overview	
Yougmoo Kim, Jeff Gregorio	(Drexel	University)  
Drexel ExCITe Center / The Music and Entertainment Technology Laboratory (MET-lab) at Drexel University is devoted to research in media technologies shaping the future of live performance and entertainment. Founded in 2005, the lab's research is ever evolving.

####Math and improvisation
Dmitri Tymoczko, Rudresh Mahantappa	(Princeton University)  
Talk and Performance with Rudresh Mahantappa (Saxophone)

####Trumpet + Personal system	
Sarah Reid (CalArts)  
Trumpet + Personal system

####100 Strange Sounds: Practice on Electroacoustic Improvisation<br>
Joo Won Park (Wayne State U.)<br>
100 Strange Sounds consists of one hundred video recordings of solo improvisations using live electronics [http://www.100strangesounds.com](http://www.100strangesounds.com). The purpose of this project was to improve the creator's technical and improvisational abilities while examining the documentation and promotional possibilities of an online video platform. The author will present the technical and aesthetic findings in completing the project by demonstrating the software and hardware setup as well as sharing the viewer data from Youtube and Google Analytics.

####Spatial constructs and concepts, rituals
John Mallia / Scott Deal (NEC studio)
John Mallia lives and works in Boston, where he is a member of the Composition Faculty, and directs the Electronic Music Studio, at the New England Conservatory of Music. His compositional process is informed by spatial constructs and concepts, and a fascination with presence, ritual, and the thresholds standing between states of existence or awareness. In addition to composing chamber music and works combining acoustic instruments with electronics, he creates fixed media compositions, and collaborates with visual artists on multimedia works, including installation.
	
####Space between these lines not dedicated<br>
Flannery Cunningham (UPenn)<br>
Space between these lines not dedicated for instrument and computer consists of an ongoing process of improvisation and musical evolution shared between a human player and a computer. The piece uses Max/MSP with Rebecca Fiebrink’s open source Wekinator machine learning software; however, contrary to the usual practice of training a machine learning system prior to performance to create rich, complex, sometimes unpredictable, but internally consistent outputs in response to inputs, in this piece the machine learning system is trained live in performance. An initial semi-random musical “seed” is used as an opening output, or performance by the computer. The player improvises in response to this, then generates a new seed for the system and improvises again. These varying improvisations and musical performances on the part of the computer are used as training data, and the system is then run. The human performer continues to improvise, and now the computer “improvises” as well, by interpolating between the initial musical seeds in often unexpected ways. The piece continues with an alternation of training and running the system. The non-human half of the partnership is also endowed with creative agency, as an “activity meter” allows the computer system to decide when it will freeze on current material in the training mode (allowing the human player to layer new musical material on top of an existing texture and create more extensive musical conditions that will elicit a similar response) and when it will generate a new seed.

####Sandy James
Generative patches for Modular and Semi-Modular Synthesizers, to be continued		

####Michelle-agnes Magalhaes
Composer, pianist, improviser, to be continued

<br><br>

---

<p align="center">
   <br><br>
  <img src="../images/IKPoster_frag10.png" width="300">
   <br><br>
</p>
